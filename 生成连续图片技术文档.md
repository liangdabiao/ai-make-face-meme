# NanoMotion 生成连续图片技术文档

## 概述

NanoMotion 是一个基于 AI 的停格动画生成系统，能够将单张图片转换为连续的动画序列。本文档详细分析了生成连续图片的完整技术实现。

## 核心技术架构

### 系统流程图

```
用户上传图片 → 姿势生成 → 图片帧生成 → 流式传输 → 前端展示
     ↓              ↓            ↓           ↓            ↓
  图片缓冲区    动作序列描述  AI图像生成  实时进度反馈  动画预览
```

## 1. 图片上传与预处理

### 1.1 前端文件处理 (`src/app/page.tsx`)

```typescript
// 文件选择处理
const handleFileSelection = useCallback((files: FileList | null) => {
  if (!files || files.length === 0) return;

  const file = files[files.length - 1]; // 获取最新选择的文件

  if (file.type.startsWith("image/")) {
    setLastSelectedFile(file);

    // 创建图片预览
    const reader = new FileReader();
    reader.onload = (e) => {
      const url = e.target?.result as string;
      setUploadPreview(url);
    };
    reader.readAsDataURL(file);
  }
}, []);
```

**关键特性：**
- 支持 `image/*` 格式的所有图片类型
- 自动生成 Base64 预览图
- 文件验证确保为图片类型
- 拖拽上传支持

### 1.2 文件传输机制

- 使用 `FormData` 包装文件数据
- 通过 POST 请求发送到 `/api/stop-motion` 端点
- 支持大文件传输（最大 800 秒处理时间）

## 2. 姿势序列生成

### 2.1 姿势生成逻辑 (`src/lib/ai.ts`)

系统使用预定义的姿势模板来生成连续的动作序列：

```typescript
const poseTemplates = [
  {
    name: "Starting pose",
    description: "Character/object in neutral starting position",
    prompt: "Character in neutral starting position, standing upright with natural posture"
  },
  {
    name: "Initial movement",
    description: "Beginning of animation sequence",
    prompt: "Character beginning to move, slight shift in weight or position"
  },
  // ... 更多模板
];
```

### 2.2 动作序列算法

```typescript
for (let i = 0; i < numPoses; i++) {
  const template = poseTemplates[i % poseTemplates.length];
  const variation = Math.floor(i / poseTemplates.length);

  // 为长序列添加变化
  if (variation > 0) {
    poseDescription += ` (Variation ${variation + 1})`;
    posePrompt += `, variation ${variation + 1}`;
  }

  poses.push({
    name: poseDescription,
    description: template.description,
    prompt: posePrompt,
    step: i + 1
  });
}
```

**技术特点：**
- 生成 12 个连续姿势（可配置）
- 模板循环确保动作连贯性
- 支持变化参数增加动作丰富度
- 平滑过渡帧自动生成

## 3. AI 图像生成

### 3.1 NanoBanana API 集成

系统使用 NanoBanana API 进行图像生成，支持多种配置选项：

```typescript
interface NanobananaOptions {
  model?: string;                    // 模型选择
  responseFormat?: 'url' | 'b64_json';  // 响应格式
  aspectRatio?: string;              // 长宽比
  imageSize?: '1K' | '2K' | '4K';   // 图像质量
  referenceImages?: string[];        // 参考图像
}
```

### 3.2 图像生成流程

#### 3.2.1 API 请求构建

```typescript
const requestBody: NanobananaRequest = {
  model: options.model || 'nano-banana',
  prompt: prompt,
  response_format: options.responseFormat || 'b64_json',
  aspect_ratio: options.aspectRatio || '4:3',
  image_size: options.imageSize || '2K',
  image: imageBuffer ? [imageBuffer.toString('base64')] : undefined
};
```

#### 3.2.2 动态提示词生成

```typescript
const prompt = `基于参考图像，生成符合以下姿势描述的静止画面帧：

姿势描述：${pose.description || pose.name || '标准姿势'}
动作步骤：${pose.step || i + 1}

要求：
- 严格遵循参考图像中角色/物体的基本外观、比例和特征
- 精确应用姿势描述中的动作要求
- 保持原始图像的光照条件和背景元素
- 确保动作自然流畅，适合逐帧动画制作
- 保持图像质量清晰，适合停止动画制作
- 保持风格一致性：颜色、纹理、材质等细节

生成一张清洁、可制作的高质量动画帧，精确匹配姿势描述要求。`;
```

### 3.3 响应处理机制

系统支持多种 API 响应格式：

```typescript
// 格式1: 标准OpenAI格式
if (data.data?.[0]?.url) {
  imageUrl = data.data[0].url;
} else if (data.data?.[0]?.b64_json) {
  // 处理完整Base64字符串
  const fullBase64String = data.data[0].b64_json;
  if (fullBase64String.startsWith('data:image/')) {
    imageData = fullBase64String.split(',')[1] || fullBase64String;
  }
}

// 格式2-4: 其他可能的响应结构
// ... 多格式兼容处理
```

## 4. 流式响应系统

### 4.1 服务器端流式传输 (`src/app/api/stop-motion/route.ts`)

```typescript
const stream = new ReadableStream({
  async start(controller) {
    const encoder = new TextEncoder();

    // 1. 发送开始进度
    const progressData = JSON.stringify({
      type: "progress",
      data: "正在分析图像并生成姿势序列..."
    }) + "\n---CHUNK_END---\n";
    controller.enqueue(encoder.encode(progressData));

    // 2. 生成并发送姿势数据
    const posesData = await generatePosesFromImageBuffer(buffer, image.type, 12);
    const posesResponse = JSON.stringify({
      type: "poses",
      data: posesData
    }) + "\n---CHUNK_END---\n";
    controller.enqueue(encoder.encode(posesResponse));

    // 3. 逐个生成图像帧
    for (let i = 0; i < posesJson.poses.length; i++) {
      // 发送当前进度
      const currentProgress = JSON.stringify({
        type: "progress",
        data: `正在生成第 ${i + 1}/${posesJson.poses.length} 帧: ${pose.name}`
      }) + "\n---CHUNK_END---\n";
      controller.enqueue(encoder.encode(currentProgress));

      // 生成图像
      const nanobananaResult = await nanobanana(prompt, buffer);

      // 发送生成的图像数据
      const resultData = JSON.stringify({
        type: "nanobanana",
        data: {
          frameIndex: i + 1,
          poseName: pose.name,
          type: "image",
          base64ImageData: nanobananaResult.base64ImageData,
          contentType: nanobananaResult.contentType || 'image/jpeg',
        },
      }) + "\n---CHUNK_END---\n";
      controller.enqueue(encoder.encode(resultData));
    }

    // 4. 发送完成信号
    const endData = JSON.stringify({
      type: "complete",
      data: "处理完成"
    }) + "\n---CHUNK_END---\n";
    controller.enqueue(encoder.encode(endData));
    controller.close();
  }
});
```

### 4.2 前端流式接收处理

```typescript
// 处理流式响应
const reader = response.body?.getReader();
const decoder = new TextDecoder();
let buffer = '';

while (true) {
  const { done, value } = await reader.read();
  if (done) break;

  const chunk = decoder.decode(value, { stream: true });
  buffer += chunk;

  // 按自定义分隔符分割
  const parts = buffer.split('\n---CHUNK_END---\n');
  buffer = parts.pop() || '';

  // 处理完整的数据块
  for (const part of parts) {
    const line = part.trim();
    if (!line) continue;

    const data = JSON.parse(line);

    switch (data.type) {
      case 'poses':
        setGeneratedPoses(data.data);
        break;
      case 'nanobanana':
        // 处理生成的图像帧
        if (data.data?.base64ImageData) {
          const dataUrl = `data:${data.data.contentType};base64,${data.data.base64ImageData}`;

          // 创建新帧
          const newFrame: Frame = {
            id: `generated-${Date.now()}-${Math.random()}`,
            url: dataUrl,
            file: new File(["generated"], "generated.png", { type: data.data.contentType })
          };
          setFrames(prev => [...prev, newFrame]);
        }
        break;
      case 'complete':
        setGenerationProgress("Animation generation complete!");
        break;
    }
  }
}
```

## 5. 帧管理与动画播放

### 5.1 帧数据结构

```typescript
interface Frame {
  id: string;        // 唯一标识符
  url: string;       // 图像URL或Data URL
  file: File;        // 原始文件对象
}
```

### 5.2 动画播放控制

```typescript
// 动画循环逻辑
useEffect(() => {
  if (isPlaying && frames.length > 0) {
    animationRef.current = setInterval(() => {
      setCurrentFrame((prev) => (prev + 1) % frames.length);
    }, 1000 / frameRate);  // 根据帧率计算间隔
  } else {
    if (animationRef.current) {
      clearInterval(animationRef.current);
    }
  }
}, [isPlaying, frames.length, frameRate]);
```

### 5.3 帧重排序功能

```typescript
const moveFrame = (fromIndex: number, toIndex: number) => {
  setFrames((prev) => {
    const newFrames = [...prev];
    const [movedFrame] = newFrames.splice(fromIndex, 1);
    newFrames.splice(toIndex, 0, movedFrame);
    return newFrames;
  });
};
```

## 6. 错误处理与容错机制

### 6.1 网络错误处理

```typescript
// API调用错误处理
if (!response.ok) {
  const errorText = await response.text();
  throw new Error(`API request failed with status ${response.status}: ${errorText}`);
}

// 网络连接问题检测
if (error instanceof Error) {
  if (error.message.includes('fetch failed')) {
    throw new Error("网络连接问题：无法连接到API服务。请检查网络连接和防火墙设置。");
  } else if (error.message.includes('timeout')) {
    throw new Error("请求超时：AI模型响应时间过长。请重试或使用更简单的提示词。");
  }
}
```

### 6.2 单帧错误隔离

```typescript
try {
  const nanobananaResult = await nanobanana(prompt, buffer);
  // 处理成功生成的帧
} catch (frameError) {
  console.error(`Error generating frame ${i + 1}:`, frameError);
  // 发送错误信息但继续处理下一帧
  const frameErrorData = JSON.stringify({
    type: "frame_error",
    data: {
      frameIndex: i + 1,
      poseName: pose.name,
      error: frameError instanceof Error ? frameError.message : "Unknown frame generation error"
    }
  });
  controller.enqueue(encoder.encode(frameErrorData));
}
```

## 7. 性能优化策略

### 7.1 内存管理

- 图像数据使用 Base64 编码直接传输，避免临时文件
- 流式传输减少内存峰值
- 及时清理已完成的数据块

### 7.2 并发控制

```typescript
// 限制最大持续时间防止资源耗尽
export const maxDuration = 800; // 800秒

// 单帧生成错误隔离，避免整体失败
for (let i = 0; i < posesJson.poses.length; i++) {
  try {
    // 生成单帧
  } catch (frameError) {
    // 记录错误但继续下一帧
  }
}
```

### 7.3 用户体验优化

- 实时进度反馈
- 渐进式图像加载
- 非阻塞UI更新
- 错误重试机制

## 8. 技术依赖与环境配置

### 8.1 核心依赖

```json
{
  "dependencies": {
    "@google/genai": "^1.17.0",    // Google AI SDK
    "motion": "^12.23.12",           // Framer Motion
    "nanoid": "^5.1.5",             // 唯一ID生成
    "next": "15.5.2",               // Next.js框架
    "react": "19.1.0"                // React 19
  }
}
```

### 8.2 环境变量配置

```bash
# NanoBanana API配置
NANO_BANANA_API_BASE_URL=https://api.nanobanana.io
NANO_BANANA_API_KEY=your_api_key_here

# 可选：Google Generative AI（如果使用）
GOOGLE_GENERATIVE_AI_API_KEY=your_gemini_key_here
```

## 9. 扩展性与未来改进

### 9.1 当前限制

- 固定12帧生成（可配置但缺乏动态调整）
- 单一图像格式输入
- 基于模板的姿势生成

### 9.2 潜在改进方向

1. **智能姿势检测**：使用计算机视觉自动分析输入图像
2. **动态帧数调整**：根据动作复杂度自动调整帧数
3. **多格式支持**：支持视频输入和多种输出格式
4. **风格迁移**：支持不同艺术风格的动画生成
5. **协作编辑**：支持多人协作的帧编辑功能

## 10. 总结

NanoMotion 的连续图片生成系统通过以下技术实现：

1. **模板驱动的姿势生成**：确保动作连贯性和专业性
2. **流式API架构**：提供实时反馈和良好的用户体验
3. **多格式兼容性**：适配不同的AI服务提供商
4. **错误隔离机制**：确保系统稳定性和容错能力
5. **内存优化策略**：支持长时间运行的大批量图像处理

该系统为停格动画制作提供了一个高效、易用且可扩展的技术解决方案。